{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# create spark session\n",
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a spark data frame that contains your favorite programming languages.\n",
    "- The name of the column should be language\n",
    "- View the schema of the dataframe\n",
    "- Output the shape of the dataframe\n",
    "- Show the first 5 records in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pandas dataframe\n",
    "\n",
    "pd_df = pd.DataFrame({'language': ['python', 'julia', 'ruby', 'R', 'C++', 'Javascript', 'Typescript', 'Swift', 'Rust']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[language: string]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create spark dataframe from panadas dataframe\n",
    "sp_df = spark.createDataFrame(pd_df)\n",
    "sp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- language: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# View the shema of the dataframe\n",
    "sp_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('language', 'string')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# another way to print schema\n",
    "sp_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+\n",
      "|summary|language|\n",
      "+-------+--------+\n",
      "|  count|       9|\n",
      "|   mean|    null|\n",
      "| stddev|    null|\n",
      "|    min|     C++|\n",
      "|    max|    ruby|\n",
      "+-------+--------+\n",
      "\n",
      "DataFrame shape:  9  x  1\n"
     ]
    }
   ],
   "source": [
    "#output the shape of the dataframe\n",
    "sp_df.describe().show()\n",
    "print(\"DataFrame shape: \", sp_df.count(), \" x \", len(sp_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|language|\n",
      "+--------+\n",
      "|  python|\n",
      "|   julia|\n",
      "|    ruby|\n",
      "|       R|\n",
      "|     C++|\n",
      "+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sp_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the mpg dataset as a spark dataframe.\n",
    "- Create 1 column of output that contains a message like the one below:\n",
    ">- The 1999 audi a4 has a 4 cylinder engine.\n",
    ">- For each vehicle.\n",
    ">- Transform the trans column so that it only contains either manual or auto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "|manufacturer|model|displ|year|cyl|     trans|drv|cty|hwy| fl|  class|\n",
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "|        audi|   a4|  1.8|1999|  4|  auto(l5)|  f| 18| 29|  p|compact|\n",
      "|        audi|   a4|  1.8|1999|  4|manual(m5)|  f| 21| 29|  p|compact|\n",
      "|        audi|   a4|  2.0|2008|  4|manual(m6)|  f| 20| 31|  p|compact|\n",
      "|        audi|   a4|  2.0|2008|  4|  auto(av)|  f| 21| 30|  p|compact|\n",
      "|        audi|   a4|  2.8|1999|  6|  auto(l5)|  f| 16| 26|  p|compact|\n",
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Spark dataframe\n",
    "import pydataset\n",
    "\n",
    "mpg = spark.createDataFrame(data(\"mpg\"))\n",
    "mpg.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[year: bigint, highway_mileage: bigint, city_mileage: bigint, cylinders: bigint]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpg.select(\n",
    "    mpg.year.alias(\"year\"), col(\"hwy\").alias(\"highway_mileage\"),\n",
    "    mpg.cty.alias(\"city_mileage\"), mpg.cyl.alias(\"cylinders\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import concat, sum, avg, min, max, count, mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------+\n",
      "|concat(The , year,  , manufacturer,  , model,  has a, cyl,  engine)|\n",
      "+-------------------------------------------------------------------+\n",
      "|The 1999 audi a4 has a4 engine                                     |\n",
      "|The 1999 audi a4 has a4 engine                                     |\n",
      "|The 2008 audi a4 has a4 engine                                     |\n",
      "|The 2008 audi a4 has a4 engine                                     |\n",
      "|The 1999 audi a4 has a6 engine                                     |\n",
      "|The 1999 audi a4 has a6 engine                                     |\n",
      "|The 2008 audi a4 has a6 engine                                     |\n",
      "|The 1999 audi a4 quattro has a4 engine                             |\n",
      "|The 1999 audi a4 quattro has a4 engine                             |\n",
      "|The 2008 audi a4 quattro has a4 engine                             |\n",
      "|The 2008 audi a4 quattro has a4 engine                             |\n",
      "|The 1999 audi a4 quattro has a6 engine                             |\n",
      "|The 1999 audi a4 quattro has a6 engine                             |\n",
      "|The 2008 audi a4 quattro has a6 engine                             |\n",
      "|The 2008 audi a4 quattro has a6 engine                             |\n",
      "|The 1999 audi a6 quattro has a6 engine                             |\n",
      "|The 2008 audi a6 quattro has a6 engine                             |\n",
      "|The 2008 audi a6 quattro has a8 engine                             |\n",
      "|The 2008 chevrolet c1500 suburban 2wd has a8 engine                |\n",
      "|The 2008 chevrolet c1500 suburban 2wd has a8 engine                |\n",
      "+-------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# concatenate string columns to create the desired output column\n",
    "description = mpg.select(concat(lit(\"The \"), mpg.year, (lit(\" \")), mpg.manufacturer, (lit(\" \")), mpg.model, (lit(\" has a\")), mpg.cyl, (lit(\" engine\"))))\n",
    "description.show(20, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+----------+\n",
      "|trans_extract|trans_replace|trans_when|\n",
      "+-------------+-------------+----------+\n",
      "|         auto|         auto|      auto|\n",
      "|       manual|       manual|    manual|\n",
      "|       manual|       manual|    manual|\n",
      "|         auto|         auto|      auto|\n",
      "|         auto|         auto|      auto|\n",
      "|       manual|       manual|    manual|\n",
      "|         auto|         auto|      auto|\n",
      "|       manual|       manual|    manual|\n",
      "|         auto|         auto|      auto|\n",
      "|       manual|       manual|    manual|\n",
      "|         auto|         auto|      auto|\n",
      "|         auto|         auto|      auto|\n",
      "|       manual|       manual|    manual|\n",
      "|         auto|         auto|      auto|\n",
      "|       manual|       manual|    manual|\n",
      "|         auto|         auto|      auto|\n",
      "|         auto|         auto|      auto|\n",
      "|         auto|         auto|      auto|\n",
      "|         auto|         auto|      auto|\n",
      "|         auto|         auto|      auto|\n",
      "+-------------+-------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Transform the trans column so that it only contains either manual or auto.\n",
    "mpg.select(\n",
    "    regexp_extract('trans', r'^(\\w+)\\(', 1).alias('trans_extract'),\n",
    "    regexp_replace('trans', r'\\(.+$', '').alias('trans_replace'),\n",
    "    when(mpg.trans.like('auto%'), 'auto').otherwise('manual').alias('trans_when')\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the tips dataset as a spark dataframe.\n",
    "- What percentage of observations are smokers?\n",
    "-  Create a column that contains the tip percentage\n",
    "- Calculate the average tip percentage for each combination of sex and smoker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|\n",
      "+----------+----+------+------+---+------+----+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|\n",
      "+----------+----+------+------+---+------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the tips dataset\n",
    "\n",
    "tips = spark.createDataFrame(pydataset.data('tips'))\n",
    "tips.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg.hwy + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg.select(mpg.hwy, mpg.hwy +1).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg.select(mpg.hwy.alias('highway_milage'), mpg.hwy +1).alias('highway_milage_plus1').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col('hwy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_col = (col('hwy')+col('cty'))/2\n",
    "mpg.select(\n",
    "    col('hwy').alias(\"highway_milage\"),\n",
    "    mpg.cty.alias('city_milage'),\n",
    "    avg_col.alias('avg_milage'),).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import regexp_extract, regexp_replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textdf = spark.createDataFrame(\n",
    "    pd.DataFrame(\n",
    "        {\n",
    "            \"address\": [\n",
    "                \"600 Navarro St ste 600, San Antonio, TX 78205\",\n",
    "                \"3130 Broadway St, San Antonio, TX 78209\",\n",
    "                \"303 Pearl Pkwy, San Antonio, TX 78215\",\n",
    "                \"1255 SW Loop 410, San Antonio, TX 78227\",\n",
    "            ]\n",
    "        }\n",
    "    )\n",
    ")\n",
    "\n",
    "textdf.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textdf.select(\n",
    "    \"address\",\n",
    "    regexp_extract(\"address\", r\"^(\\d+)\", 1).alias(\"street_no\"),\n",
    "    regexp_extract(\"address\", r\"^\\d+\\s([\\w\\s]+?),\", 1).alias(\"street\"),\n",
    ").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textdf.select(\n",
    "    \"address\",\n",
    "    regexp_replace(\"address\", r\"^.*?,\\s*\", \"\").alias(\"city_state_zip\"),\n",
    ").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg.filter(mpg.cyl == 4).where(mpg[\"class\"] == \"subcompact\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg.select(mpg.hwy, when(mpg.hwy > 25, \"good_mileage\").alias(\"mpg_desc\")).show(\n",
    "    12\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg.select(\n",
    "    mpg.hwy,\n",
    "    when(mpg.hwy > 25, \"good_mileage\")\n",
    "    .otherwise(\"bad_mileage\")\n",
    "    .alias(\"mpg_desc\"),\n",
    ").show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import asc, desc\n",
    "from pyspark.sql.functions import when\n",
    "from pyspark.sql.functions import concat, sum, avg, min, max, count, mean\n",
    "from pyspark.sql.functions import lit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg.groupBy(mpg.cyl)\n",
    "mpg.groupBy(col(\"cyl\"))\n",
    "mpg.groupBy(\"cyl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg.groupBy(mpg.cyl).agg(avg(mpg.cty), avg(mpg.hwy)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg.groupBy(\"cyl\", \"class\").agg(avg(mpg.cty), avg(mpg.hwy)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg.rollup(\"cyl\").count().sort(\"cyl\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg.rollup(\"cyl\").agg(expr(\"avg(hwy)\")).sort(\"cyl\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg.rollup(\"cyl\", \"class\").mean(\"hwy\").sort(col(\"cyl\"), col(\"class\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
